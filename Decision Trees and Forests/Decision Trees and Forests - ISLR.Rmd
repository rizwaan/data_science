---
title: "Decision Trees and Forests"
author: "Rizwaan Adil"
date: "February 7, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



[Source](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/courseware/4cd5971758e84840b24d91c763df6ce8/e9481751b91d4f25b7a6d98fa5b7d371/)

***
#### Package Management
```{r,  message=FALSE}
library(ISLR)
library(tree)
library(dplyr)

```


***
#### Data Manipulation
```{r}

attach(Carseats)
hist(Sales,breaks = 15)



```

Create a categorical response from Sales column
```{r}
High=ifelse(Sales>8,"Yes","No")
Carseats=data.frame(Carseats,High)
head(Carseats)
```

<br>

***
#### Fit Tree Model

Exclude Sales from the model
```{r}
m.tree=tree(High~.-Sales,data=Carseats)
summary(m.tree)
plot(m.tree)
text(m.tree,pretty = 0)
```


Look at the details..   
- More than 20 nodes here.. making it unintuitive.  

Detailed summary of the tree
```{r}
m.tree
```

<br>

#### Use model for prediction


```{r}
set.seed(1011)

## Test Train Split. There are 400 observation. 250 for training set
## Get an index
train= sample(1:nrow(Carseats),size = 250)

#Generate a tree model using training set
m1tree = tree(High~.-Sales
              ,data = Carseats
              ,subset = train)
plot(m1tree);text(m1tree,pretty=0)



```

<br>
Predict using the test set
```{r}

m1tree.pred=predict(m1tree,newdata = Carseats[-train,],type = "class")

##Generate the confusion matrix
with(Carseats[-train,], table(m1tree.pred,High))

#Accuracy is 70%
(72+33)/150
```

***
#### Pruning the tree

Using cross validation, prune the tree to a better size.
Then regrow the tree on the original data to compare with first model


Find the best size of the tree without sacrificing much of accuracy

```{r}
cv.carseats<-cv.tree(m1tree,FUN=prune.misclass) # Use miscalssificate error to prune the tree
cv.carseats
plot(cv.carseats)

```

The misclass error bottoms out at about 10. 
This provides a guidance about pruning the original tree for the best size


Time to prune the tree

```{r}
prune.m1tree= prune.misclass(m1tree,best = 13)
plot(prune.m1tree);text(prune.m1tree,pretty=0)

```

This tree is far less bushy and quite interpretable

Now use this pruned model to predict again

```{r}
final.tree.pred=predict(prune.m1tree,newdata = Carseats[-train,],type = "class")
with(Carseats[-train,], table(final.tree.pred,High))

## Accuracy = 69 %
(72+32)/150

```


Thus, by pruning the tree we have a more interpretable tree with just a 1% drop in accuracy



****

#### Random Forests and Boosting


#####Load packages

```{r, message=FALSE}
require(randomForest)
require(MASS)


```

<br>

##### Data Management

Response variable is medv
```{r}Bo
dim(Boston) # 500 rows
names(Boston)

```
<br>

##### Split data

```{r}
train.rf=sample(1:nrow(Boston),300) # 300 out of 500 as training set



```


##### Fit Model

```{r}
rf.boston=randomForest(medv~.,data = Boston,subset = train.rf)
rf.boston

```

>Note that the mtry(no of variables to select from for a split at each node is 4 .. approx close to sqrt of total variables(13))   
>Also the MSR and %Var explained are computed using [OOB estimates](https://en.wikipedia.org/wiki/Out-of-bag_error)
>By default 500 trees are fit

Plot the model  

```{r}
plot(rf.boston)

```


Error flattens out at around 100 trees.


##### Effect of varying the mtry component on the test error  

Capture OOB error and test error by varying mtry in the rf model

```{r}
oob.err=double(13)
test.err= double(13)

for (mtry in 1:13){
  fit=randomForest(formula = medv~.
                   ,data = Boston
                   ,subset = train.rf
                   ,mtree=400
                   ,mtry=mtry)
  oob.err[mtry]=fit$mse[400] # Last item of the mse component is the overall MSE; same logic for getting the R squared .. use fit$rsq
  pred=predict(fit,Boston[-train.rf,])
  test.err[mtry]=with(Boston[-train.rf,],mean((medv-pred)^2))
  cat(mtry," ")
}
  

```


Plot the errors

```{r}
matplot(1:mtry,cbind(test.err,oob.err),pch = 19, col = c("red", "blue"), type = "b", ylab = "Mean Squared Error")


legend("topright", legend = c("OOB", "Test"), pch = 19, col = c("red", "blue"))

```

At mtry = 4 we have a good mix of low error and low complexity for the RF model.


***
#### Boosting


Boosting works by building a lot of shallow trees and employs error based weights during bagging for prediction  

##### Package Management
```{r}


require(gbm)

```


##### Fit the boosting model to Boston data

```{r, message=FALSE}

gbm.fit<-gbm(formula = medv~.
             ,data = Boston[train.rf,]
             ,interaction.depth = 5
             ,n.trees = 10000
             ,shrinkage = .01)

summary(gbm.fit)

```
>Tip: Use cross validation to adjust the parameters.
>In Azure ML use the Tune HyperParameters module


Plot the response vs top 2 variables

```{r}
par(mfrow=c(1,2))
plot(gbm.fit,i="lstat") # relation bw lstat (low status income group) and medv is invversely proportional
plot(gbm.fit,i="rm") # direct relation between number of rooms in the house and the price
```

##### Prediction using Boosting model

Plot test error for different values of the tree parameter

```{r}
num_trees<-seq(100,10000,100)
predmat<-predict(gbm.fit
                 ,newdata = Boston[-train.rf,]
                 ,n.trees = num_trees) # This model will return a matrix 
dim(predmat)
head(predmat,2) # 206 rows of predicion for different number of trees on columns

```
<br>
Calculate the RMS error  
Note that predmat is a matrix and medv is a vector. 
Output would be a matrix  


```{r}
boost.err<-with(Boston[-train.rf,]
     ,apply((predmat-medv)^2,2,mean) )

boost.err # RMS for every n.tree value

```

Plot the errors vs the tree num

```{r}
par(mfrow=c(1,2))
plot(num_trees,boost.err) ##Boosting Model
matplot(1:mtry,cbind(test.err,oob.err),pch = 19, col = c("red", "blue"), type = "b", ylab = "Mean Squared Error") ## RF Model
```

As seen here, optimum number of trees is about 3000.
Also the error range is below 10.. lower than RF model

